{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4caa3ca-e31b-48b5-9534-6b24535804c6",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357245d-b459-4756-a37a-e7dfe74cd60a",
   "metadata": {},
   "source": [
    "### Original Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b994393c-5c9f-46c2-a23f-53e0f1aa8e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Class 0)</th>\n",
       "      <th>Recall (Class 0)</th>\n",
       "      <th>F1-Score (Class 0)</th>\n",
       "      <th>Precision (Class 1)</th>\n",
       "      <th>Recall (Class 1)</th>\n",
       "      <th>F1-Score (Class 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision (Class 0)  Recall (Class 0)  \\\n",
       "0  Logistic Regression      0.53                 0.81              0.55   \n",
       "1        Random Forest      0.80                 0.80              1.00   \n",
       "2              XGBoost      0.71                 0.80              0.85   \n",
       "\n",
       "   F1-Score (Class 0)  Precision (Class 1)  Recall (Class 1)  \\\n",
       "0                0.65                 0.21              0.49   \n",
       "1                0.89                 0.00              0.00   \n",
       "2                0.82                 0.19              0.14   \n",
       "\n",
       "   F1-Score (Class 1)  \n",
       "0                0.30  \n",
       "1                0.00  \n",
       "2                0.16  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create the table for model comparison based on the provided results for the original dataset\n",
    "data_original_dataset = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [0.53, 0.80, 0.71],\n",
    "    'Precision (Class 0)': [0.81, 0.80, 0.80],\n",
    "    'Recall (Class 0)': [0.55, 1.00, 0.85],\n",
    "    'F1-Score (Class 0)': [0.65, 0.89, 0.82],\n",
    "    'Precision (Class 1)': [0.21, 0.00, 0.19],\n",
    "    'Recall (Class 1)': [0.49, 0.00, 0.14],\n",
    "    'F1-Score (Class 1)': [0.30, 0.00, 0.16]\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_original_dataset_results = pd.DataFrame(data_original_dataset)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_original_dataset_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ded0b-3031-4aa4-9443-b9b30810ee3d",
   "metadata": {},
   "source": [
    "**Conclusion:** \n",
    "- **Logistic Regression is the most balanced** model but still struggles to accurately predict defaulters, with an overall low performance for Class 1.\n",
    "- **Random Forest** performs very well for non-defaulters (Class 0) but **completely fails to identify defaulters (Class 1)**. This is a significant problem, as identifying defaulters is critical.\n",
    "- **XGBoost** Offers a better balance than Random Forest, though its performance on defaulters is still weak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f595b6-b791-4286-8aff-062b0b0bc171",
   "metadata": {},
   "source": [
    "### After Aplying SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "777c731d-10fc-4be1-95c8-87cd29d18c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Class 0)</th>\n",
       "      <th>Recall (Class 0)</th>\n",
       "      <th>F1-Score (Class 0)</th>\n",
       "      <th>Precision (Class 1)</th>\n",
       "      <th>Recall (Class 1)</th>\n",
       "      <th>F1-Score (Class 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision (Class 0)  Recall (Class 0)  \\\n",
       "0  Logistic Regression      0.65                  0.8              0.76   \n",
       "1        Random Forest      0.80                  0.8              1.00   \n",
       "2              XGBoost      0.71                  0.8              0.85   \n",
       "\n",
       "   F1-Score (Class 0)  Precision (Class 1)  Recall (Class 1)  \\\n",
       "0                0.78                 0.19              0.23   \n",
       "1                0.89                 0.00              0.00   \n",
       "2                0.83                 0.21              0.15   \n",
       "\n",
       "   F1-Score (Class 1)  \n",
       "0                0.21  \n",
       "1                0.00  \n",
       "2                0.18  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create the table for model comparison based on the provided results after applying SMOTE\n",
    "data_smote = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [0.65, 0.80, 0.71],\n",
    "    'Precision (Class 0)': [0.80, 0.80, 0.80],\n",
    "    'Recall (Class 0)': [0.76, 1.00, 0.85],\n",
    "    'F1-Score (Class 0)': [0.78, 0.89, 0.83],\n",
    "    'Precision (Class 1)': [0.19, 0.00, 0.21],\n",
    "    'Recall (Class 1)': [0.23, 0.00, 0.15],\n",
    "    'F1-Score (Class 1)': [0.21, 0.00, 0.18]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_smote_results = pd.DataFrame(data_smote)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_smote_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad446f-d81c-4894-b347-8d5083b0c556",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- **Random Forest** has the highest accuracy but fails to identify defaulters, making it unsuitable when Class 1 (defaulters) is important.\n",
    "\n",
    "- **Logistic Regression** is more balanced, providing slightly better recall and F1-score for defaulters than the other models, but still needs improvement.\n",
    "\n",
    "- **XGBoost** offers better results than Random Forest for defaulters, but overall performance remains weak."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb1ddd3-bfb8-4422-b0a2-e8ba7961cce5",
   "metadata": {},
   "source": [
    "### After Aplying Random Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6775bbfb-15cf-441e-9a83-f0997c976d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Class 0)</th>\n",
       "      <th>Recall (Class 0)</th>\n",
       "      <th>F1-Score (Class 0)</th>\n",
       "      <th>Precision (Class 1)</th>\n",
       "      <th>Recall (Class 1)</th>\n",
       "      <th>F1-Score (Class 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision (Class 0)  Recall (Class 0)  \\\n",
       "0  Logistic Regression      0.52                 0.80              0.54   \n",
       "1        Random Forest      0.51                 0.79              0.53   \n",
       "2              XGBoost      0.48                 0.78              0.48   \n",
       "\n",
       "   F1-Score (Class 0)  Precision (Class 1)  Recall (Class 1)  \\\n",
       "0                0.64                 0.20              0.47   \n",
       "1                0.64                 0.19              0.43   \n",
       "2                0.60                 0.18              0.45   \n",
       "\n",
       "   F1-Score (Class 1)  \n",
       "0                0.28  \n",
       "1                0.26  \n",
       "2                0.25  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Create the table for model comparison based on the provided results\n",
    "data_undersampling_full = {\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [0.52, 0.51, 0.48],\n",
    "    'Precision (Class 0)': [0.80, 0.79, 0.78],\n",
    "    'Recall (Class 0)': [0.54, 0.53, 0.48],\n",
    "    'F1-Score (Class 0)': [0.64, 0.64, 0.60],\n",
    "    'Precision (Class 1)': [0.20, 0.19, 0.18],\n",
    "    'Recall (Class 1)': [0.47, 0.43, 0.45],\n",
    "    'F1-Score (Class 1)': [0.28, 0.26, 0.25]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_undersampling_full_results = pd.DataFrame(data_undersampling_full)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_undersampling_full_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4862902-b45a-4137-8ced-576183b6db94",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "- Logistic Regression performs the best overall in terms of balancing accuracy and performance for both classes. While it doesn’t perform well for defaulters (Class 1), it has the highest accuracy and best handles non-defaulters (Class 0).\n",
    "\n",
    "- Random Forest has slightly better recall for defaulters (Class 1) compared to Logistic Regression, but its performance is quite close overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571e07b-2954-436b-8f5c-0af36873b332",
   "metadata": {},
   "source": [
    "### After Aplying Random Over Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e425a5ba-9209-439b-9195-e1a1589de0d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision (Class 0)</th>\n",
       "      <th>Recall (Class 0)</th>\n",
       "      <th>F1-Score (Class 0)</th>\n",
       "      <th>Precision (Class 1)</th>\n",
       "      <th>Recall (Class 1)</th>\n",
       "      <th>F1-Score (Class 1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision (Class 0)  Recall (Class 0)  \\\n",
       "0  Logistic Regression      0.54                 0.56              0.54   \n",
       "1              XGBoost      0.89                 0.95              0.82   \n",
       "2        Random Forest      0.97                 0.97              0.98   \n",
       "\n",
       "   F1-Score (Class 0)  Precision (Class 1)  Recall (Class 1)  \\\n",
       "0                0.55                 0.53              0.54   \n",
       "1                0.88                 0.83              0.96   \n",
       "2                0.97                 0.98              0.97   \n",
       "\n",
       "   F1-Score (Class 1)  \n",
       "0                0.54  \n",
       "1                0.89  \n",
       "2                0.97  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results Comparison Among the models\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create the data for model comparison after random oversampling\n",
    "data = {\n",
    "    'Model': ['Logistic Regression', 'XGBoost', 'Random Forest'],\n",
    "    'Accuracy': [0.54, 0.89, 0.97],\n",
    "    'Precision (Class 0)': [0.56, 0.95, 0.97],\n",
    "    'Recall (Class 0)': [0.54, 0.82, 0.98],\n",
    "    'F1-Score (Class 0)': [0.55, 0.88, 0.97],\n",
    "    'Precision (Class 1)': [0.53, 0.83, 0.98],\n",
    "    'Recall (Class 1)': [0.54, 0.96, 0.97],\n",
    "    'F1-Score (Class 1)': [0.54, 0.89, 0.97]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df_results = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d108dbf-ce50-460e-b8ae-fcec7719bc55",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "- **Logistic Regression** *underperformed* with an accuracy of 0.54. It struggled to accurately distinguish defaulters, showing balanced but low precision and recall for both classes.\n",
    "- **XGBoost** *performed well*, achieving an **accuracy of 0.89**. It demonstrated strong precision for non-defaulters and excellent recall for defaulters, making it a good candidate for identifying defaulters while maintaining overall performance.\n",
    "- **Random Forest** was the best performer with an **accuracy of 0.97**, showing **near-perfect precision and recall for both defaulters and non-defaulters**. It effectively handled the imbalanced data and provides a robust solution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04523cf9-a08c-4ab7-a350-58ee2b4fef2c",
   "metadata": {},
   "source": [
    "## Discusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb46b5-bf58-4c59-8514-63a42e9c52e5",
   "metadata": {},
   "source": [
    "#### Why Random Forest is the Best Performed Model:\n",
    "- **Ensemble Learning:** Random Forest combines the predictions of multiple decision trees to make a final prediction, leading to better generalization and performance.\n",
    "- **Handling Class Imbalance:** It handles imbalanced classes well, especially when class_weight='balanced' is used, as the model adjusts for the imbalance in the data.\n",
    "- **Overfitting Control:** Random Forest reduces overfitting by averaging multiple decision trees, improving the overall performance on unseen data.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e856bf-8a69-48fb-8856-2587bc0a23f5",
   "metadata": {},
   "source": [
    "#### Why XGBoost Performed Better, Because:\n",
    "\n",
    "- Its **ability to handle complex relationships**, **manage class imbalances effectively**, and **avoid overfitting**. Its excellent recall for defaulters makes it a strong choice for your problem of predicting loan defaults.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c343292b-cb47-448a-8948-905da7a02e18",
   "metadata": {},
   "source": [
    "#### Why Logistic Regression  Couldn't Perform Well :\n",
    "\n",
    "- **Imbalanced Dataset:** struggles with imbalanced data where one class significantly outweighs the other. In this dataset, there are far more non-defaulters (class 0) than defaulters (class 1), causing the model to focus more on predicting the majority class (class 0), while ignoring the minority class (class 1).\n",
    "\n",
    "- **Linear Model:**  This is a linear model, meaning it assumes a linear relationship between the input features and the target variable. If the relationship between your features (e.g., loan amount, interest rate) and the target (default status) is more complex, logistic regression may not capture this complexity well.\n",
    "\n",
    "- **No Feature Interactions:**  LR does not automatically account for interactions between features unless explicitly modeled. In contrast, models like Random Forest and XGBoost naturally capture interactions between features, making them better suited for complex datasets.\n",
    "\n",
    "- **Sensitivity to Outliers:** can be sensitive to outliers, which might affect its performance if outliers exist in this dataset.\n",
    "\n",
    "- **Scaling Issues:** If features were not properly scaled (especially numerical ones like loan amount, interest rate), Logistic Regression may struggle to converge or properly separate the classes.\n",
    "\n",
    "Addressing these issues, such as balancing the dataset or feature scaling, could improve Logistic Regression’s performance, but it may still fall short compared to the more flexible tree-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db9a053-7f60-4b5d-8795-565bb2fb819d",
   "metadata": {},
   "source": [
    "### Why Didn't Choose SVM or Dicision Tree for Model Building in this Case\n",
    "\n",
    "- **Decision Tree**:\n",
    "    - Prone to overfitting with complex data, making it less robust compared to ensemble methods.\n",
    "    - Can be unstable as small changes in data lead to drastically different results.\n",
    "    - Lacks regularization, which can result in poor generalization.\n",
    "\n",
    "- **SVM**:\n",
    "    - Computationally expensive for large datasets and harder to scale.\n",
    "    - Struggles with imbalanced data unless special techniques like adjusting class weights are applied.\n",
    "    - Tuning for non-linear relationships (using kernel tricks) can be complex and less effective compared to tree-based models.\n",
    "    - Less interpretable than decision tree-based methods.\n",
    "\n",
    "*XGBoost and Random Forest were better suited because they handle class imbalance, capture complex patterns, prevent overfitting, and scale efficiently with large datasets, leading to their stronger performance.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a14f717-7be2-4e7c-aec8-37323c488248",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77fc99-896b-40fb-84ee-bb26c1ad25d1",
   "metadata": {},
   "source": [
    "In contrast, *Random Forest* and *XGBoost* are *tree-based models* that can handle *non-linear relationships* and *imbalanced data* better, which explains their **superior performance**.\n",
    "\n",
    "**Random Forest** is likely the **optimal choice** based on its exceptional performance, with **XGBoost** also being a **strong alternative**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ec40d-c23d-4f5e-b1bc-d61ccca1eceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
